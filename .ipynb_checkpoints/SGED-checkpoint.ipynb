{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarks\n",
    "\n",
    "* Data normalization\n",
    "    * Mobilenet expects data from -1 to 1\n",
    "        * Normalize Input Data or Include in Model\n",
    "        * TFLite Conversion must fit according to decision\n",
    "    * Ground Truth Data: for better inspection Data multiplied by 80. Undo the change in the Data Input Pipeline\n",
    "* Overview in Tutorials:\n",
    "    * tf.function\n",
    "* Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 10:33:56.934020: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-03 10:33:56.934080: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (david-ThinkPad-X1-Yoga-Gen-6): /proc/driver/nvidia/version does not exist\n",
      "2022-05-03 10:33:56.944427: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#!for a in /sys/bus/pci/devices/*; do echo 0 | sudo tee -a $a/numa_node; done\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "#import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import DataProcessing.data_processing as data_processing\n",
    "import Nets.backbones as backbones\n",
    "import Nets.features as features\n",
    "import Nets.losses as losses\n",
    "import Nets.metrics as metrics\n",
    "import Nets.tools as tools\n",
    "\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "#np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'SceneNet'\n",
    "MODEL = 'SGED'\n",
    "OUTPUT_TRAIN = 'outputTrain'\n",
    "OUTPUT_TEST = 'outputTest'\n",
    "HALF = True\n",
    "\n",
    "IMG_SIZE_HEIGHT = 1280\n",
    "IMG_SIZE_WIDTH = 720\n",
    "NUM_CLASSES = 3\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "#MAX_IMG_TRAIN = 1000\n",
    "#MAX_IMG_TEST = 200\n",
    "MAX_IMG_TRAIN = 1500\n",
    "MAX_IMG_TEST = 300\n",
    "\n",
    "CACHE = True\n",
    "SEED = None\n",
    "#SEED = 5\n",
    "\n",
    "BACKBONE = \"MobileNetV2\"\n",
    "output = 5\n",
    "BACKBONE_OUTPUT = [1,2,3,output] #keep in mind: list start with 0.\n",
    "BACKBONE_WEIGHTS = \"imagenet\"\n",
    "ALPHA = 1.0\n",
    "FINE_TUNING = True\n",
    "TRAINABLE_OUTPUT_LAYER_IDX = 3 #(4-1) as indexint starts with 0\n",
    "\n",
    "\n",
    "\n",
    "#EPOCHS = 30\n",
    "EPOCHS = 10\n",
    "fine_tune_epochs = 20\n",
    "\n",
    "#Model Callback\n",
    "MODEL_SAVE_EPOCH_FREQ = 5\n",
    "DEL_CHECKPOINTS_OLD = True\n",
    "\n",
    "# TENSORBOARD:\n",
    "TENSORBOARD = False\n",
    "DEL_OLD_TENSORBOARD = True\n",
    "\n",
    "# SAVE\n",
    "SAVE = True\n",
    "\n",
    "# LOSS\n",
    "WeightedMultiLabelSigmoidEdgeLoss = False\n",
    "if WeightedMultiLabelSigmoidEdgeLoss:\n",
    "    beta_upper = 0.95\n",
    "    beta_lower = 0.05\n",
    "    class_weighted = False\n",
    "\n",
    "FocalLoss = True\n",
    "if FocalLoss:\n",
    "    gamma=2 \n",
    "    alpha=1 \n",
    "    weighted_beta=True \n",
    "    beta_upper=0.9 \n",
    "    beta_lower=0.1\n",
    "    class_weighted=False\n",
    "\n",
    "THRESHOLD_EDGE_WIDTH = 1\n",
    "\n",
    "#TESTING\n",
    "test = False\n",
    "if test:\n",
    "    EPOCHS = 1\n",
    "    MAX_IMG_TRAIN = 6\n",
    "    MAX_IMG_TEST = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset, Preprocess Images and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/SemesterProject/Datasets/SceneNet/outputTrain/half/images\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/david/SemesterProject/SGED/DataProcessing/data_processing.py\", line 76, in parse_image  *\n        image = tf.io.read_file(img_path)\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m paths, files \u001b[38;5;241m=\u001b[39m data_processing\u001b[38;5;241m.\u001b[39mpath_definitions(HALF, MODEL, DATA, OUTPUT_TRAIN, OUTPUT_TEST)\n\u001b[1;32m      5\u001b[0m data_processing\u001b[38;5;241m.\u001b[39mclean_model_directories(paths, DEL_CHECKPOINTS_OLD, DEL_OLD_TENSORBOARD)\n\u001b[0;32m----> 7\u001b[0m train_ds, img_count_train \u001b[38;5;241m=\u001b[39m \u001b[43mdata_processing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTRAIN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE_HEIGHT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE_WIDTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHALF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_IMG_TRAIN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m data_processing\u001b[38;5;241m.\u001b[39mdataset_processing(train_ds, CACHE\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, SHUFFLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, BATCH_SIZE \u001b[38;5;241m=\u001b[39m BATCH_SIZE, PREFETCH \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, img_count \u001b[38;5;241m=\u001b[39m img_count_train)\n\u001b[1;32m     10\u001b[0m test_ds, img_count_test \u001b[38;5;241m=\u001b[39m data_processing\u001b[38;5;241m.\u001b[39mloader(paths,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST\u001b[39m\u001b[38;5;124m\"\u001b[39m, IMG_SIZE_HEIGHT, IMG_SIZE_WIDTH, HALF, MAX_IMG_TEST)\n",
      "File \u001b[0;32m~/SemesterProject/SGED/DataProcessing/data_processing.py:116\u001b[0m, in \u001b[0;36mloader\u001b[0;34m(paths, mode, HEIGHT, WIDTH, HALF, MAX_IMG)\u001b[0m\n\u001b[1;32m    114\u001b[0m files_filtered \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m MAX_IMG \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    115\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(files_filtered)\n\u001b[0;32m--> 116\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: preprocess(x, HEIGHT, WIDTH, HALF),\n\u001b[1;32m    118\u001b[0m                       num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# image_count = len(glob(os.path.join(paths[\"IMAGE\"][mode], \"*.png\")))\u001b[39;00m\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2018\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MapDataset(\u001b[38;5;28mself\u001b[39m, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2019\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2020\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5234\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m   5233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m-> 5234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5236\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5238\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5240\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/SemesterProject/tf/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/david/SemesterProject/SGED/DataProcessing/data_processing.py\", line 76, in parse_image  *\n        image = tf.io.read_file(img_path)\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(SEED)\n",
    "\n",
    "paths, files = data_processing.path_definitions(HALF, MODEL, DATA, OUTPUT_TRAIN, OUTPUT_TEST)\n",
    "\n",
    "data_processing.clean_model_directories(paths, DEL_CHECKPOINTS_OLD, DEL_OLD_TENSORBOARD)\n",
    "\n",
    "train_ds, img_count_train = data_processing.loader(paths,\"TRAIN\", IMG_SIZE_HEIGHT, IMG_SIZE_WIDTH, HALF, MAX_IMG_TRAIN)\n",
    "train_ds = data_processing.dataset_processing(train_ds, CACHE=CACHE, SHUFFLE = True, BATCH_SIZE = BATCH_SIZE, PREFETCH = True, img_count = img_count_train)\n",
    "\n",
    "test_ds, img_count_test = data_processing.loader(paths,\"TEST\", IMG_SIZE_HEIGHT, IMG_SIZE_WIDTH, HALF, MAX_IMG_TEST)\n",
    "test_ds = data_processing.dataset_processing(test_ds, CACHE=CACHE, SHUFFLE = False, BATCH_SIZE = BATCH_SIZE, PREFETCH = True, img_count = img_count_test)\n",
    "\n",
    "#print(\"Memory Usage corresponds to: \",tf.config.experimental.get_memory_info('GPU:0')['current'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for image,label in train_ds.take(1):\n",
    "    sample_image, sample_mask = image,label\n",
    "\n",
    "tools.plot_images(images=sample_image, labels=sample_mask, predictions=None, BS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HALF:\n",
    "    output_dims = (int(IMG_SIZE_HEIGHT/2), int(IMG_SIZE_WIDTH/2))\n",
    "else:\n",
    "    output_dims = (IMG_SIZE_HEIGHT, IMG_SIZE_WIDTH)\n",
    "\n",
    "# BACKBONE\n",
    "backbone, output_names = backbones.get_backbone(name=BACKBONE,weights=BACKBONE_WEIGHTS,\n",
    "                                          height=IMG_SIZE_HEIGHT,width=IMG_SIZE_WIDTH,\n",
    "                                          alpha=ALPHA, output_layer = BACKBONE_OUTPUT, \n",
    "                                          trainable_idx=TRAINABLE_OUTPUT_IDX)\n",
    "\n",
    "# DASPP\n",
    "daspp = features.DASPP(layers[-1])\n",
    "\n",
    "# Decoder\n",
    "decoded = features.decoder(daspp, layers[1], output_dims=output_dims, NUM_CLASSES=NUM_CLASSES, num_side_filters = 6)\n",
    "\n",
    "\n",
    "# SIDE FEATURES\n",
    "# TODO: Upsampling: Nearest NEIGHBOUR ?\n",
    "upsample_side_1 = features.side_feature_SGED(backbone.output[0], output_dims=output_dims ,interpolation=\"bilinear\")\n",
    "upsample_side_2 = features.side_feature_SGED(backbone.output[1], output_dims=output_dims ,interpolation=\"bilinear\")\n",
    "upsample_side_3 = features.side_feature_SGED(backbone.output[2], output_dims=output_dims ,interpolation=\"bilinear\")\n",
    "\n",
    "# TODO: adaptive weight fusion ?\n",
    "# CONCATENATE\n",
    "side_outputs = [upsample_side_1,upsample_side_2,upsample_side_3,decoded]\n",
    "concat = features.shared_concatenation(side_outputs,NUM_CLASSES)\n",
    "\n",
    "# FUSE_CLASSIFICATION\n",
    "output = features.fused_classification(concat,NUM_CLASSES,name=\"output\")\n",
    "\n",
    "model = tf.keras.Model(inputs = backbone.input, outputs = output)\n",
    "\n",
    "if WeightedMultiLabelSigmoidEdgeLoss:\n",
    "    loss = lambda y_true, y_pred : losses.WeightedMultiLabelSigmoidLoss(y_true,y_pred,beta_lower=beta_lower,beta_upper=beta_upper, class_weighted=class_weighted)\n",
    "elif FocalLoss:\n",
    "    loss = lambda y_true, y_pred : losses.FocalLossEdges(y_true, y_pred, gamma=gamma, alpha=alpha, weighted_beta=weighted_beta,beta_lower=beta_lower,beta_upper=beta_upper, class_weighted=class_weighted)\n",
    "else:\n",
    "    raise ValueError(\"either FocalLoss or WeightedMultiLabelSigmoidLoss must be True\")\n",
    "\n",
    "#tf.keras.utils.plot_model(model,show_shapes = True,to_file = 'h.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORBOARD:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir /home/david/SemesterProject/Models/SGED/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# same Loss function is applied to both outputs, thus I only pass one loss function\n",
    "\n",
    "# learning rate schedule\n",
    "# base_learning_rate = 0.00125\n",
    "base_learning_rate = 0.0015\n",
    "end_learning_rate = 0.0001\n",
    "decay_step = np.ceil(img_count_train / BATCH_SIZE)*EPOCHS\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(base_learning_rate,decay_steps = decay_step,end_learning_rate = end_learning_rate, power = 0.9)\n",
    "\n",
    "frequency = int(np.ceil(img_count_train / BATCH_SIZE)*MODEL_SAVE_EPOCH_FREQ)\n",
    "\n",
    "logdir = os.path.join(paths['TBLOGS'], datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath = paths[\"CKPT\"]+ \"/ckpt-loss={loss:.2f}-epoch={epoch:.2f}\",save_weights_only=False,save_best_only=False,monitor=\"val_loss\",verbose=1,save_freq= frequency),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1)]\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss=loss,\n",
    "              metrics=[metrics.BinaryAccuracyEdges(threshold_prediction=0),\n",
    "                       metrics.RecallEdges(threshold_prediction=0, threshold_edge_width=THRESHOLD_EDGE_WIDTH),\n",
    "                       metrics.PrecisionEdges(threshold_prediction=0, threshold_edge_width=THRESHOLD_EDGE_WIDTH)])\n",
    "\n",
    "\n",
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=test_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses = [\"loss\"]\n",
    "plot_metrics = [\"accuracy_edges\", \"recall_edges\", \"precision_edges\"]\n",
    "\n",
    "path = os.path.join(paths[\"FIGURES\"],\"training.svg\")\n",
    "\n",
    "tools.plot_training_results(res=history.history, losses=plot_losses, metrics=plot_metrics, SAVE=SAVE, path=path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### F1:\n",
    "\n",
    "m = metrics.F1Edges(threshold_prediction = 0, threshold_edge_width = THRESHOLD_EDGE_WIDTH)\n",
    "\n",
    "for img, label in test_ds:\n",
    "    img, label = img, label\n",
    "\n",
    "    \n",
    "    pred = model.predict(img)\n",
    "\n",
    "    m.update_state(label, pred[0])\n",
    "    \n",
    "print(m.result()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in test_ds.take(1):\n",
    "    img, label = img, label\n",
    "    \n",
    "    predictions = model.predict(img)\n",
    "    \n",
    "predictions = tools.predict_class_postprocessing(predictions, threshold = 0.5)\n",
    "\n",
    "path = os.path.join(paths[\"FIGURES\"],\"images\")\n",
    "tools.plot_images(images=img, labels=label, predictions=predictions,SAVE = SAVE, path = path, BS=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FINE_TUNING:\n",
    "\n",
    "    # Let's take a look to see how many layers are in the base model\n",
    "    print(\"Number of layers in the base model: \", len(backbone.layers))\n",
    "\n",
    "    # Fine-tune from this layer onwards\n",
    "    fine_tune_output = output_names[2]\n",
    "\n",
    "    backbone.trainable = True\n",
    "\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "    for layer in backbone.layers:\n",
    "        layer.trainable = False\n",
    "        if layer.name == fine_tune_output:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    total_epochs =  EPOCHS + fine_tune_epochs\n",
    "\n",
    "    base_learning_rate = 0.0015\n",
    "    end_learning_rate = 0.0005\n",
    "    decay_step = np.floor(img_count_train / BATCH_SIZE)*fine_tune_epochs\n",
    "    lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        base_learning_rate,decay_steps = decay_step,end_learning_rate = end_learning_rate, power = 0.9)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                  loss=loss,\n",
    "                  metrics=[metrics.BinaryAccuracyEdges(threshold_prediction=0),\n",
    "                           metrics.RecallEdges(threshold_prediction=0, threshold_edge_width=THRESHOLD_EDGE_WIDTH),\n",
    "                           metrics.PrecisionEdges(threshold_prediction=0, threshold_edge_width=THRESHOLD_EDGE_WIDTH)])\n",
    "\n",
    "    history_fine = model.fit(train_ds, epochs=total_epochs, \n",
    "                               initial_epoch=history.epoch[-1],validation_data=train_ds.take(1), \n",
    "                               callbacks=callbacks)\n",
    "    \n",
    "    plot_losses = [\"loss\"]\n",
    "    plot_metrics = [\"accuracy_edges\", \"recall_edges\", \"precision_edges\"]\n",
    "    \n",
    "    path = os.path.join(paths[\"FIGURES\"],\"fine_tuning_training.svg\")\n",
    "    \n",
    "    tools.plot_training_results(res=history.history, res_fine = history_fine.history, \n",
    "                                losses=plot_losses, metrics=plot_metrics, SAVE=SAVE, path=path, EPOCHS = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc += history_fine[\"...\"]\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "#plt.ylim([0.8, 1])\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "#plt.ylim([0, 1.0])\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img, label in test_ds.take(1):\n",
    "    img, label = img, label\n",
    "\n",
    "    \n",
    "predictions = model.predict(img)\n",
    "predictions = tools.predict_class_postprocessing(predictions, threshold = 0.5)\n",
    "\n",
    "path = os.path.join(paths[\"FIGURES\"],\"fine_tuning_images_0,5\")\n",
    "tools.plot_images(images=img, labels=label, predictions=predictions,SAVE = SAVE, path = path, BS=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SAVE:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m     custom_objects \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinaryAccuracy_Edges\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy_Edges,\n\u001b[1;32m      5\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall_Edges\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics\u001b[38;5;241m.\u001b[39mRecall_Edges,\n\u001b[1;32m      6\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision_Edges\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics\u001b[38;5;241m.\u001b[39mPrecision_Edges,\n\u001b[1;32m      7\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m\"\u001b[39m:loss}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "if SAVE:\n",
    "    model.save(paths[\"MODEL\"])\n",
    "    \n",
    "    custom_objects = {\"BinaryAccuracyEdges\": metrics.BinaryAccuracy_Edges,\n",
    "                      \"RecallEdges\": metrics.Recall_Edges,\n",
    "                      \"PrecisionEdges\": metrics.Precision_Edges,\n",
    "                      \"lambda\":loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_real(path,HEIGHT,WIDTH):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.expand_dims(image,axis = 0)\n",
    "    image = tf.image.resize(image,(IMG_SIZE_HEIGHT, IMG_SIZE_WIDTH))\n",
    "    pred = model.predict(image)\n",
    "    \n",
    "    val_max = tf.reduce_max(pred, axis = -1)\n",
    "    idx_max = tf.argmax(pred, axis = -1) + 1\n",
    "\n",
    "    predictions = tf.where(val_max >= 0, idx_max, 0)\n",
    "\n",
    "    predictions = tf.expand_dims(predictions, axis = -1)\n",
    "\n",
    "    return image,predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m Data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m imgs:\n\u001b[0;32m----> 9\u001b[0m     img, mask \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mIMG_SIZE_HEIGHT\u001b[49m\u001b[43m,\u001b[49m\u001b[43mIMG_SIZE_WIDTH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     Data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m     11\u001b[0m     Data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mask)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mpredict_real\u001b[0;34m(path, HEIGHT, WIDTH)\u001b[0m\n\u001b[1;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(image,axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(image,(IMG_SIZE_HEIGHT, IMG_SIZE_WIDTH))\n\u001b[0;32m----> 7\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(image)\n\u001b[1;32m      9\u001b[0m val_max \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_max(pred, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m idx_max \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(pred, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "IMG_SIZE_HEIGHT = 1280\n",
    "IMG_SIZE_WIDTH = 720\n",
    "\n",
    "imgs = [1,2,3,4,5, 6]\n",
    "path = '/home/david/test_images/'\n",
    "Data = {'img':[],'mask':[]}\n",
    "\n",
    "for i in imgs:\n",
    "    img, mask = predict_real(path+str(i)+'.png',IMG_SIZE_HEIGHT,IMG_SIZE_WIDTH)\n",
    "    Data['img'].append(img)\n",
    "    Data['mask'].append(mask)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 50))\n",
    "size = len(Data['img'])\n",
    "for k in range(size):\n",
    "    plt.subplot(size,2, k*2+1)\n",
    "    plt.title(\"Images\")\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(Data['img'][k][0,:,:,:]))\n",
    "    plt.subplot(size,2, k*2+2)\n",
    "    plt.title(\"Estimation\")\n",
    "    plt.imshow(Data['mask'][k][0,:,:],cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "if SAVE:\n",
    "    plt.savefig(os.path.join(paths[\"FIGURES\"],'real.svg'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addtional Elements to Consider in other Projects\n",
    "\n",
    "* Data augmentation for small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

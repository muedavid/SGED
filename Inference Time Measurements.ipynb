{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarks\n",
    "\n",
    "* Data normalization\n",
    "    * Mobilenet expects data from -1 to 1\n",
    "        * Normalize Input Data or Include in Model\n",
    "        * TFLite Conversion must fit according to decision\n",
    "    * Ground Truth Data: for better inspection Data multiplied by 80. Undo the change in the Data Input Pipeline\n",
    "* Overview in Tutorials:\n",
    "    * tf.function\n",
    "    * Repeat addapted Version of using Build in methods for training, ...\n",
    "    * Save models using keras\n",
    "        * CaseNet first real model: check implementation of Frey if a Layer needs to be written\n",
    "        * other Example: depth seperable dilated convolution,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!for a in /sys/bus/pci/devices/*; do echo 0 | sudo tee -a $a/numa_node; done\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "#import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "import DataProcessing.data_processing as data_processing\n",
    "import Nets.backbones as backbones\n",
    "import Nets.features as features\n",
    "import Nets.losses as losses\n",
    "import Nets.metrics as metrics\n",
    "import Nets.visualize as visualize\n",
    "import Nets.tools as tools\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "#np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter Notebook\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--model_loaded', type=str, required=False, default=None)\n",
    "parser.add_argument('--data_base_model', type=str, required=False, default=None)\n",
    "\n",
    "parser.add_argument('--sigmoid', action='store_true', default=False)\n",
    "parser.add_argument('--focal', action='store_true', default=False)\n",
    "\n",
    "parser.add_argument('--beta_upper', type=float, required=False, default=None)\n",
    "parser.add_argument('--gamma', type=float, required=False, default=None)\n",
    "parser.add_argument('--alpha', type=float, required=False, default=None)\n",
    "\n",
    "file_name = None\n",
    "try:\n",
    "    file_name = __file__\n",
    "except:\n",
    "    print(\"Jupyter Notebook\")\n",
    "       \n",
    "if file_name is None:\n",
    "    args = parser.parse_args(\"\")\n",
    "    args.train_model = False\n",
    "    args.cache = True\n",
    "    args.save = True\n",
    "    args.sigmoid = False\n",
    "    args.focal = True\n",
    "else:    \n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generall Parameters\n",
    "#MODEL_LOADED = 'CASENET_FOCAL_LOSS_0.5_g2_a2' if args.model_loaded is None else args.model_loaded\n",
    "MODEL_LOADED = 'SGED_FOCAL_LOSS_0.6_g2_a2' if args.model_loaded is None else args.model_loaded\n",
    "DATA_BASE_MODEL_LOADED = 'SceneNetFloorTiledTextureRandom' if args.data_base_model is None else args.data_base_model\n",
    "\n",
    "TRAIN_DS = 'Train'\n",
    "TEST_DS = 'Test'\n",
    "TEST_HARD_DS = 'Test Hard'\n",
    "TEST_IMG_DS = 'Test IMG'\n",
    "HALF = True\n",
    "\n",
    "# Dataset Loading Parameters\n",
    "IMG_SIZE_HEIGHT = 1280\n",
    "IMG_SIZE_WIDTH = 720\n",
    "NUM_CLASSES = 3\n",
    "MAX_IMG_TRAIN = 100\n",
    "MAX_IMG_TEST = 25\n",
    "SEED = None\n",
    "NUM_EVAL = 500;\n",
    "\n",
    "\n",
    "# Model Parameters\n",
    "SAVE = args.save\n",
    "TRAIN_MODEL = args.train_model\n",
    "\n",
    "\n",
    "# LOSS\n",
    "weighted_multi_label_sigmoid_edge_loss = args.sigmoid\n",
    "focal_loss = args.focal\n",
    "\n",
    "beta_upper = 0.5 if args.beta_upper is None else args.beta_upper\n",
    "beta_lower = 1.0 - beta_upper\n",
    "gamma=2.0 if args.gamma is None else args.gamma \n",
    "alpha=2.0 if args.alpha is None else args.alpha\n",
    "class_weighted = True\n",
    "weighted_beta=True\n",
    "\n",
    "THRESHOLD_EDGE_WIDTH_REAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset, Preprocess Images and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 13:54:13.770960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:13.779091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:13.779263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:13.780199: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-07 13:54:13.780690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:13.780835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:13.780936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:14.248689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:14.248811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:14.248901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 13:54:14.248957: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-07 13:54:14.248982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9754 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2022-06-07 13:54:14.322875: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5529600000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "data = tf.random.uniform(\n",
    "    [NUM_EVAL, IMG_SIZE_HEIGHT, IMG_SIZE_WIDTH, 3],\n",
    "    minval=0,\n",
    "    maxval=255,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    seed=None,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "dataset = dataset.batch(1)\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "paths, files = data_processing.path_definitions(HALF, \"\", \"\", \"\", \"\", \"\", \"\", MODEL_LOADED, DATA_BASE_MODEL_LOADED, make_dirs=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weighted_multi_label_sigmoid_edge_loss:\n",
    "    loss = lambda y_true, y_pred : losses.weighted_multi_label_sigmoid_loss(y_true,y_pred,beta_lower=beta_lower,beta_upper=beta_upper, class_weighted=class_weighted)\n",
    "elif focal_loss:\n",
    "    loss = lambda y_true, y_pred : losses.focal_loss_edges(y_true, y_pred, gamma=gamma, alpha=alpha, weighted_beta=weighted_beta,beta_lower=beta_lower,beta_upper=beta_upper, class_weighted=class_weighted)\n",
    "else:\n",
    "    raise ValueError(\"either FocalLoss or WeightedMultiLabelSigmoidLoss must be True\")\n",
    "    \n",
    "\n",
    "custom_objects = {\"BinaryAccuracyEdges\": metrics.BinaryAccuracyEdges,\n",
    "                  \"F1Edges\": metrics.F1Edges,\n",
    "                  \"<lambda>\":loss}\n",
    "\n",
    "model = tf.keras.models.load_model(paths[\"MODEL LOADED\"], custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed 24.768 seconds.\n",
      "Time per Image 0.0495\n",
      "Frame per second 20.187386\n"
     ]
    }
   ],
   "source": [
    "# Preheat GPU:\n",
    "i = 0\n",
    "for d in dataset:\n",
    "    model.predict(d)\n",
    "    i += 1\n",
    "    if i == 50:\n",
    "        break\n",
    "\n",
    "# evaluate:\n",
    "start = time.perf_counter()\n",
    "for d in dataset:\n",
    "    a = model.predict(d)\n",
    "elapsed = time.perf_counter() - start\n",
    "print('Elapsed %.3f seconds.' % elapsed)\n",
    "print('Time per Image {:.4f}'.format(elapsed/NUM_EVAL))\n",
    "print('Frame per second {:4f}'.format(NUM_EVAL / elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
